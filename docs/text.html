

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pewanalytics.text: Text Tools &mdash; pewanalytics 1.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="pewanalytics.stats: Statistical Tools" href="stats.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> pewanalytics
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="stats.html">Statistical Tools</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text Tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#general-text-processing-tools">General Text Processing Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="#date-extraction">Date Extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topic-modeling">Topic Modeling</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pewanalytics</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>pewanalytics.text: Text Tools</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/text.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pewanalytics-text-text-tools">
<h1>pewanalytics.text: Text Tools<a class="headerlink" href="#pewanalytics-text-text-tools" title="Permalink to this headline">¶</a></h1>
<p>In the <code class="xref py py-mod docutils literal notranslate"><span class="pre">pewanalytics.text</span></code> module, you’ll find a variety of utilities for working with text data.</p>
<div class="section" id="general-text-processing-tools">
<h2>General Text Processing Tools<a class="headerlink" href="#general-text-processing-tools" title="Permalink to this headline">¶</a></h2>
<p>The main <code class="xref py py-mod docutils literal notranslate"><span class="pre">pewanalytics.text</span></code> module contains a variety of general tools for processing text.</p>
<p><strong>Functions</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter_parts_of_speech</span></code>(text[, filter_pos, …])</p></td>
<td><p>Retain words associated with parts of speech in the text if <cite>exclude=False</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_fuzzy_partial_ratio</span></code>(text1, text2[, …])</p></td>
<td><p>Useful to calculate similarity of two strings that are of noticeably different lengths.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_fuzzy_ratio</span></code>(text1, text2[, throw_loud_fail])</p></td>
<td><p>Uses Levenshtein Distance to calculate similarity of two strings.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">has_fragment</span></code>(text, fragment)</p></td>
<td><p>Checks whether a substring (“fragment”) is contained within a larger string (“text”).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_fragments</span></code>(text, fragments[, …])</p></td>
<td><p>Iteratively remove fragments from a string.</p></td>
</tr>
</tbody>
</table>
<dl class="function">
<dt>
<code class="sig-name descname">has_fragment</code><span class="sig-paren">(</span><em class="sig-param">text</em>, <em class="sig-param">fragment</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/__init__.html#has_fragment"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Checks whether a substring (“fragment”) is contained within a larger string (“text”). Uses the <cite>pewtils.decode_text</cite>
function to process both the text and the fragment when running this check.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – The text to search</p></li>
<li><p><strong>fragment</strong> (<em>str</em>) – The fragment to search for</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Whether or not the text contains the fragment</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text</span> <span class="k">import</span> <span class="n">has_fragment</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;testing one two three&quot;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">has_fragment</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;one two&quot;</span><span class="p">)</span>
<span class="kc">True</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">has_fragment</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;four&quot;</span><span class="p">)</span>
<span class="kc">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt>
<code class="sig-name descname">remove_fragments</code><span class="sig-paren">(</span><em class="sig-param">text</em>, <em class="sig-param">fragments</em>, <em class="sig-param">throw_loud_fail=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/__init__.html#remove_fragments"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Iteratively remove fragments from a string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – The text toremove the fragments from</p></li>
<li><p><strong>fragments</strong> (<em>list</em>) – A list of string fragments to search for and remove</p></li>
<li><p><strong>throw_loud_fail</strong> (<em>bool</em>) – bool; whether or not to raise an error if text decoding fails (default=False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The original string, minus any parts that matched the fragments provided</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text</span> <span class="k">import</span> <span class="n">remove_fragments</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;testing one two three&quot;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">remove_fragments</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;one two&quot;</span><span class="p">])</span>
<span class="s2">&quot;testing  three&quot;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">remove_fragments</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;testing&quot;</span><span class="p">,</span> <span class="s2">&quot;three&quot;</span><span class="p">])</span>
<span class="s2">&quot; one two &quot;</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt>
<code class="sig-name descname">filter_parts_of_speech</code><span class="sig-paren">(</span><em class="sig-param">text</em>, <em class="sig-param">filter_pos=None</em>, <em class="sig-param">exclude=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/__init__.html#filter_parts_of_speech"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Retain words associated with parts of speech in the text if <cite>exclude=False</cite>.
If <cite>exclude=True</cite>, exclude words associated with parts of speech.
Default is Noun (NN), Proper Noun (NNP) and Adjective (JJ)</p>
<div class="line-block">
<div class="line">The full list of POS is here: <a class="reference external" href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html">https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html</a></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – The string to process</p></li>
<li><p><strong>filter_pos</strong> (<em>list</em>) – Array of part of speech tags (default is ‘NN’, ‘NNP’, and ‘JJ’)</p></li>
<li><p><strong>exclude</strong> – If <cite>True</cite>, the function will remove words that match to the specified parts of speech; by default     this function <em>filters to</em> POS matches instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A string comprised solely of words that matched (or did not match) to the specified parts of speech,     depending on the value of <cite>exclude</cite></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text</span> <span class="k">import</span> <span class="n">filter_parts_of_speech</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is a very exciting sentence that can serve as a functional example&quot;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">filter_parts_of_speech</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">filter_pos</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;NN&quot;</span><span class="p">])</span>
<span class="s1">&#39;sentence example&#39;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">filter_parts_of_speech</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">filter_pos</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;JJ&quot;</span><span class="p">],</span> <span class="n">exclude</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="s1">&#39;This is a very sentence that can serve as a example&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt>
<code class="sig-name descname">get_fuzzy_ratio</code><span class="sig-paren">(</span><em class="sig-param">text1</em>, <em class="sig-param">text2</em>, <em class="sig-param">throw_loud_fail=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/__init__.html#get_fuzzy_ratio"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses Levenshtein Distance to calculate similarity of two strings.  Measures how the edit distance compares
to the overall length of the texts. Uses the <cite>fuzzywuzzy</cite> library in Python 2, and the <cite>rapidfuzz</cite> library in     Python 3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text1</strong> (<em>str</em>) – First string</p></li>
<li><p><strong>text2</strong> – Second string</p></li>
<li><p><strong>throw_loud_fail</strong> (<em>bool</em>) – bool; whether or not to raise an error if text decoding fails (default=False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Levenshtein ratio between the two strings</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text</span> <span class="k">import</span> <span class="n">get_fuzzy_ratio</span>

<span class="n">text1</span> <span class="o">=</span> <span class="s2">&quot;This is a sentence.&quot;</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s2">&quot;This is a slightly difference sentence.&quot;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">get_fuzzy_ratio</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">)</span>
<span class="mf">64.28571428571428</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt>
<code class="sig-name descname">get_fuzzy_partial_ratio</code><span class="sig-paren">(</span><em class="sig-param">text1</em>, <em class="sig-param">text2</em>, <em class="sig-param">throw_loud_fail=False</em>, <em class="sig-param">timeout=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/__init__.html#get_fuzzy_partial_ratio"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Useful to calculate similarity of two strings that are of noticeably different lengths.  Allows for the possibility
that one text is a subset of the other; finds the largest overlap and computes the Levenshtein ratio on that.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text1</strong> (<em>str</em>) – First string</p></li>
<li><p><strong>text2</strong> (<em>str</em>) – Second string</p></li>
<li><p><strong>timeout</strong> (<em>int</em>) – The number of seconds to wait before giving up</p></li>
<li><p><strong>throw_loud_fail</strong> (<em>bool</em>) – bool; whether or not to raise an error if text decoding fails (default=False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The partial Levenshtein ratio between the two texts</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Accepts kwarg timeout</dt>
<dd class="field-even"><p></p></dd>
</dl>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text</span> <span class="k">import</span> <span class="n">get_partial_fuzzy_ratio</span>

<span class="n">text1</span> <span class="o">=</span> <span class="s2">&quot;This is a sentence.&quot;</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s2">&quot;This is a sentence, but with more text.&quot;</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">get_partial_fuzzy_ratio</span><span class="p">(</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">)</span>
<span class="mf">100.0</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="date-extraction">
<h2>Date Extraction<a class="headerlink" href="#date-extraction" title="Permalink to this headline">¶</a></h2>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">pewanalytics.text.dates</span></code> submodule contains a helper class for extracting dates from text.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">DateFinder</span></code>([preprocessing_patterns])</p></td>
<td><p>A helper class to search for dates in text using a series of regular expressions and a parser from <cite>dateutil</cite>.</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-name descname">DateFinder</code><span class="sig-paren">(</span><em class="sig-param">preprocessing_patterns=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/dates.html#DateFinder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A helper class to search for dates in text using a series of regular expressions and a parser from <cite>dateutil</cite>.     Verifies that <cite>dateutil</cite> did not auto-fill missing values in the date. Time information will be automatically     cleared out, but you can also pass a list of additional regular expression patterns (as strings) to define other     patterns that should be cleared out before scanning for dates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>preprocessing_patterns</strong> (<em>list</em>) – Optional list of additional patterns to clear out prior to searching for dates.</p>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_dates</span></code>(text, cutoff_date_start, …)</p></td>
<td><p>Return all of the dates (in text form and as datetime) in the text variable that fall within the specified         window of dates (inclusive).</p></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text.dates</span> <span class="k">import</span> <span class="n">DateFinder</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;January 1, 2018 and 02/01/2019 and Mar. 1st 2020&quot;</span>
<span class="n">low_bound</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">high_bound</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2021</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">finder</span> <span class="o">=</span> <span class="n">DateFinder</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dates</span> <span class="o">=</span> <span class="n">finder</span><span class="o">.</span><span class="n">find_dates</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">low_bound</span><span class="p">,</span> <span class="n">high_bound</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dates</span>
<span class="p">[</span>
    <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2018</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;January 1, 2018 &#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;Mar. 1st 2020&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;02/01/2019 &#39;</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
<dl class="method">
<dt>
<code class="sig-name descname">find_dates</code><span class="sig-paren">(</span><em class="sig-param">text</em>, <em class="sig-param">cutoff_date_start</em>, <em class="sig-param">cutoff_date_end</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/dates.html#DateFinder.find_dates"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return all of the dates (in text form and as datetime) in the text variable that fall within the specified         window of dates (inclusive).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – The text to scan for dates</p></li>
<li><p><strong>cutoff_date_start</strong> (<cite>datetime.date</cite>) – No dates will be returned if they fall before this date</p></li>
<li><p><strong>cutoff_date_end</strong> (<cite>datetime.date</cite>) – No dates will be returned if they fall after this date</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of tuples containing (datetime object, raw date text)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="named-entity-recognition">
<h2>Named Entity Recognition<a class="headerlink" href="#named-entity-recognition" title="Permalink to this headline">¶</a></h2>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">pewanalytics.text.ner</span></code> submodule contains a helper class for extracting named entities from text.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">NamedEntityExtractor</span></code>([method])</p></td>
<td><p>A wrapper around NLTK and SpaCy for named entity extraction.</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-name descname">NamedEntityExtractor</code><span class="sig-paren">(</span><em class="sig-param">method='spacy'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/ner.html#NamedEntityExtractor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A wrapper around NLTK and SpaCy for named entity extraction. May be expanded to include more libraries in the     future.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>method</strong> (<em>str</em>) – Specify the library to use when extracting methods. Options are ‘nltk’, ‘spacy’, ‘all’. If     ‘all’ is selected, both libraries will be used and the union will be returned. (Default=’spacy’)</p>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">extract</span></code>(text)</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">param text</dt>
<dd class="field-odd"><p>a string from which to extract named entities</p>
</dd>
</dl>
</p></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text.ner</span> <span class="k">import</span> <span class="n">NamedEntityExtractor</span>
<span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;inaugural&quot;</span><span class="p">)</span>
<span class="n">fileid</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">inaugural</span><span class="o">.</span><span class="n">fileids</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">inaugural</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileid</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">ner</span> <span class="o">=</span> <span class="n">NamedEntityExtractor</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;nltk&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ner</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="p">{</span>
    <span class="s1">&#39;ORGANIZATION&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;Parent&#39;</span><span class="p">,</span> <span class="s1">&#39;Invisible Hand&#39;</span><span class="p">,</span> <span class="s1">&#39;Great Author&#39;</span><span class="p">,</span> <span class="s1">&#39;House&#39;</span><span class="p">,</span> <span class="s1">&#39;Constitution&#39;</span><span class="p">,</span> <span class="s1">&#39;Senate&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Human Race&#39;</span><span class="p">,</span> <span class="s1">&#39;Representatives&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;PERSON&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Almighty Being&#39;</span><span class="p">],</span>
    <span class="s1">&#39;GPE&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Heaven&#39;</span><span class="p">,</span> <span class="s1">&#39;United States&#39;</span><span class="p">,</span> <span class="s1">&#39;American&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">ner</span> <span class="o">=</span> <span class="n">NamedEntityExtractor</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;spacy&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ner</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="p">{</span>
    <span class="s1">&#39;ORGANIZATION&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;House of Representatives&#39;</span><span class="p">,</span> <span class="s1">&#39;Senate&#39;</span><span class="p">,</span> <span class="s1">&#39;Parent of the Human Race&#39;</span><span class="p">],</span>
    <span class="s1">&#39;DATE&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;present month&#39;</span><span class="p">,</span> <span class="s1">&#39;every day&#39;</span><span class="p">,</span> <span class="s1">&#39;14th day&#39;</span><span class="p">,</span> <span class="s1">&#39;years&#39;</span><span class="p">],</span>
    <span class="s1">&#39;ORDINAL&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="s1">&#39;fifth&#39;</span><span class="p">],</span>
    <span class="s1">&#39;GPE&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;United States&#39;</span><span class="p">],</span>
    <span class="s1">&#39;NORP&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;republican&#39;</span><span class="p">,</span> <span class="s1">&#39;American&#39;</span><span class="p">],</span>
    <span class="s1">&#39;LAW&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Constitution&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">ner</span> <span class="o">=</span> <span class="n">NamedEntityExtractor</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ner</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="p">{</span>
    <span class="s1">&#39;ORGANIZATION&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;Representatives&#39;</span><span class="p">,</span> <span class="s1">&#39;Great Author&#39;</span><span class="p">,</span> <span class="s1">&#39;House&#39;</span><span class="p">,</span> <span class="s1">&#39;Parent&#39;</span><span class="p">,</span> <span class="s1">&#39;House of Representatives&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Parent of the Human Race&#39;</span><span class="p">,</span> <span class="s1">&#39;Invisible Hand&#39;</span><span class="p">,</span> <span class="s1">&#39;Human Race&#39;</span><span class="p">,</span> <span class="s1">&#39;Senate&#39;</span><span class="p">,</span> <span class="s1">&#39;Constitution&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;PERSON&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Almighty Being&#39;</span><span class="p">],</span>
    <span class="s1">&#39;GPE&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Heaven&#39;</span><span class="p">,</span> <span class="s1">&#39;United States&#39;</span><span class="p">,</span> <span class="s1">&#39;American&#39;</span><span class="p">],</span>
    <span class="s1">&#39;DATE&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;every day&#39;</span><span class="p">,</span> <span class="s1">&#39;present month&#39;</span><span class="p">,</span> <span class="s1">&#39;14th day&#39;</span><span class="p">,</span> <span class="s1">&#39;years&#39;</span><span class="p">],</span>
    <span class="s1">&#39;ORDINAL&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="s1">&#39;fifth&#39;</span><span class="p">],</span>
    <span class="s1">&#39;NORP&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;republican&#39;</span><span class="p">,</span> <span class="s1">&#39;American&#39;</span><span class="p">],</span>
    <span class="s1">&#39;LAW&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Constitution&#39;</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<dl class="method">
<dt>
<code class="sig-name descname">extract</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/ner.html#NamedEntityExtractor.extract"><span class="viewcode-link">[source]</span></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> – a string from which to extract named entities</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dictionary of entities organized by their category</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="topic-modeling">
<h2>Topic Modeling<a class="headerlink" href="#topic-modeling" title="Permalink to this headline">¶</a></h2>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">pewanalytics.text.topics</span></code> submodule contains a standardized class for training and applying topic models using several different libraries.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopicModel</span></code>(df, text_col, method[, …])</p></td>
<td><p>A wrapper around various topic modeling algorithms and libraries, intended to provide a standardized way to train     and apply models.</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt>
<em class="property">class </em><code class="sig-name descname">TopicModel</code><span class="sig-paren">(</span><em class="sig-param">df</em>, <em class="sig-param">text_col</em>, <em class="sig-param">method</em>, <em class="sig-param">num_topics=None</em>, <em class="sig-param">max_ngram_size=2</em>, <em class="sig-param">holdout_pct=0.25</em>, <em class="sig-param">use_tfidf=False</em>, <em class="sig-param">**vec_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A wrapper around various topic modeling algorithms and libraries, intended to provide a standardized way to train     and apply models. When you initialize a <cite>TopicModel</cite>, it will fit a vectorizer, and split the data into a train     and test set if <cite>holdout_pct</cite> is provided. For more information about the available implementations, refer to the     documentation for the <cite>fit()</cite> method below.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – Pandas DataFrame</p></li>
<li><p><strong>text_col</strong> (<em>str</em>) – Name of the column containing text</p></li>
<li><p><strong>method</strong> (<em>str</em>) – The topic model implementation to use. Options are: sklearn_lda, sklearn_nmf, gensim_lda,     gensim_hdp, corex</p></li>
<li><p><strong>num_topics</strong> (<em>int</em>) – The number of topics to extract. Required for every method except <cite>gensim_hdp</cite>.</p></li>
<li><p><strong>max_ngram_size</strong> (<em>int</em>) – Maximum ngram size (2=bigrams, 3=trigrams, etc)</p></li>
<li><p><strong>holdout_pct</strong> (<em>float</em>) – Proportion of the documents to hold out for goodness-of-fit scoring</p></li>
<li><p><strong>use_tfidf</strong> (<em>bool</em>) – Whether to use binary counts or a TF-IDF representation</p></li>
<li><p><strong>vec_kwargs</strong> – All remaining arguments get passed to TfidfVectorizer or CountVectorizer</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>([df])</p></td>
<td><p>Fits a model using the method specified when initializing the <cite>TopicModel</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_document_topics</span></code>(df, **kwargs)</p></td>
<td><p>Takes a DataFrame and returns a document-topic DataFrame (rows=documents, columns=topics)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_features</span></code>(df[, keep_sparse])</p></td>
<td><p>Uses the trained vectorizer to process a dataframe and return a feature matrix.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_fit_params</span></code>(**kwargs)</p></td>
<td><p>Internal helper function to set defaults depending on the specified model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_score</span></code>()</p></td>
<td><p>Returns goodness-of-fit scores for certain models, based on the holdout documents.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_topics</span></code>([include_weights, top_n])</p></td>
<td><p>Returns a list, equal in length to the number of topics, where each item is a list of words or word-weight tuples.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_topics</span></code>([include_weights, top_n])</p></td>
<td><p>Prints the top words for each topic from a trained model.</p></td>
</tr>
</tbody>
</table>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pewanalytics.text.topics</span> <span class="k">import</span> <span class="n">TopicModel</span>

<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;movie_reviews&quot;</span><span class="p">)</span>
<span class="n">reviews</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;fileid&quot;</span><span class="p">:</span> <span class="n">fileid</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">movie_reviews</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">fileid</span><span class="p">)}</span> <span class="k">for</span> <span class="n">fileid</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">movie_reviews</span><span class="o">.</span><span class="n">fileids</span><span class="p">()]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">reviews</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">TopicModel</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;sklearn_nmf&quot;</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="n">num_topics</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">use_tfidf</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">Initialized</span> <span class="n">sklearn_nmf</span> <span class="n">topic</span> <span class="n">model</span> <span class="k">with</span> <span class="mi">3285</span> <span class="n">features</span>
<span class="mi">1600</span> <span class="n">training</span> <span class="n">documents</span><span class="p">,</span> <span class="mi">400</span> <span class="n">testing</span> <span class="n">documents</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">print_topics</span><span class="p">()</span>
<span class="mi">0</span><span class="p">:</span> <span class="n">bad</span><span class="p">,</span> <span class="n">really</span><span class="p">,</span> <span class="n">know</span><span class="p">,</span> <span class="n">don</span><span class="p">,</span> <span class="n">plot</span><span class="p">,</span> <span class="n">people</span><span class="p">,</span> <span class="n">scene</span><span class="p">,</span> <span class="n">movies</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">scenes</span>
<span class="mi">1</span><span class="p">:</span> <span class="n">star</span><span class="p">,</span> <span class="n">trek</span><span class="p">,</span> <span class="n">star</span> <span class="n">trek</span><span class="p">,</span> <span class="n">effects</span><span class="p">,</span> <span class="n">wars</span><span class="p">,</span> <span class="n">star</span> <span class="n">wars</span><span class="p">,</span> <span class="n">special</span><span class="p">,</span> <span class="n">special</span> <span class="n">effects</span><span class="p">,</span> <span class="n">movies</span><span class="p">,</span> <span class="n">series</span>
<span class="mi">2</span><span class="p">:</span> <span class="n">jackie</span><span class="p">,</span> <span class="n">films</span><span class="p">,</span> <span class="n">chan</span><span class="p">,</span> <span class="n">jackie</span> <span class="n">chan</span><span class="p">,</span> <span class="n">hong</span><span class="p">,</span> <span class="n">master</span><span class="p">,</span> <span class="n">drunken</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">tarantino</span><span class="p">,</span> <span class="n">brown</span>
<span class="mi">3</span><span class="p">:</span> <span class="n">life</span><span class="p">,</span> <span class="n">man</span><span class="p">,</span> <span class="n">best</span><span class="p">,</span> <span class="n">characters</span><span class="p">,</span> <span class="n">new</span><span class="p">,</span> <span class="n">love</span><span class="p">,</span> <span class="n">world</span><span class="p">,</span> <span class="n">little</span><span class="p">,</span> <span class="n">does</span><span class="p">,</span> <span class="n">great</span>
<span class="mi">4</span><span class="p">:</span> <span class="n">alien</span><span class="p">,</span> <span class="n">series</span><span class="p">,</span> <span class="n">aliens</span><span class="p">,</span> <span class="n">characters</span><span class="p">,</span> <span class="n">films</span><span class="p">,</span> <span class="n">television</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">quite</span><span class="p">,</span> <span class="n">mars</span><span class="p">,</span> <span class="n">action</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">doc_topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_document_topics</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">doc_topics</span>
       <span class="n">topic_0</span>   <span class="n">topic_1</span>   <span class="n">topic_2</span>   <span class="n">topic_3</span>   <span class="n">topic_4</span>
<span class="mi">0</span>     <span class="mf">0.723439</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>
<span class="mi">1</span>     <span class="mf">0.289801</span>  <span class="mf">0.050055</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>
<span class="mi">2</span>     <span class="mf">0.375149</span>  <span class="mf">0.000000</span>  <span class="mf">0.030691</span>  <span class="mf">0.059088</span>  <span class="mf">0.143679</span>
<span class="mi">3</span>     <span class="mf">0.152961</span>  <span class="mf">0.010386</span>  <span class="mf">0.000000</span>  <span class="mf">0.121412</span>  <span class="mf">0.015865</span>
<span class="mi">4</span>     <span class="mf">0.294005</span>  <span class="mf">0.100426</span>  <span class="mf">0.000000</span>  <span class="mf">0.137630</span>  <span class="mf">0.051241</span>
<span class="o">...</span>        <span class="o">...</span>       <span class="o">...</span>       <span class="o">...</span>       <span class="o">...</span>       <span class="o">...</span>
<span class="mi">1995</span>  <span class="mf">0.480983</span>  <span class="mf">0.070431</span>  <span class="mf">0.135178</span>  <span class="mf">0.256951</span>  <span class="mf">0.000000</span>
<span class="mi">1996</span>  <span class="mf">0.139986</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>  <span class="mf">0.107430</span>  <span class="mf">0.000000</span>
<span class="mi">1997</span>  <span class="mf">0.141545</span>  <span class="mf">0.005990</span>  <span class="mf">0.081986</span>  <span class="mf">0.387859</span>  <span class="mf">0.057025</span>
<span class="mi">1998</span>  <span class="mf">0.029228</span>  <span class="mf">0.023342</span>  <span class="mf">0.043713</span>  <span class="mf">0.280877</span>  <span class="mf">0.107551</span>
<span class="mi">1999</span>  <span class="mf">0.044863</span>  <span class="mf">0.000000</span>  <span class="mf">0.000000</span>  <span class="mf">0.718677</span>  <span class="mf">0.000000</span>
</pre></div>
</div>
<dl class="method">
<dt>
<code class="sig-name descname">get_features</code><span class="sig-paren">(</span><em class="sig-param">df</em>, <em class="sig-param">keep_sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.get_features"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the trained vectorizer to process a dataframe and return a feature matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The DataFrame to vectorize (must have <cite>self.text_col</cite> in it)</p></li>
<li><p><strong>keep_sparse</strong> (<em>bool</em>) – Whether or not to keep the feature matrix in sparse format (default=False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A Pandas DataFrame of features or a sparse matrix, depending on the value of <cite>keep_sparse</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">get_fit_params</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.get_fit_params"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Internal helper function to set defaults depending on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> – Arguments passed to <cite>self.fit()</cite></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Arguments to pass to the model</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">df=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.fit"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fits a model using the method specified when initializing the <cite>TopicModel</cite>. Details on model-specific         parameters are below:</p>
<p><strong>sklearn_lda</strong></p>
<p>Fits a model using <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.LatentDirichletAllocation</span></code>. For more information on         available parameters, please refer to the official documentation: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The dataframe to train the model on (must contain <cite>self.text_col</cite>)</p></li>
<li><p><strong>alpha</strong> – Represents document-topic density. When values are higher, documents will be comprised of more         topics; when values are lower, documents will be primarily comprised of only a few topics. This parameter         is used instead of the doc_topic_prior sklearn parameter, and will be passed along to sklearn using the         formula: <cite>doc_topic_prior = alpha / num_topics</cite></p></li>
<li><p><strong>beta</strong> – Represents topic-word density. When values are higher, topics will be comprised of more words;         when values are lower, only a few words will be loaded onto each topic. This parameter is used instead of the         topic_word_prior sklearn parameter, and will be passed along to sklearn using the formula:         <cite>topic_word_prior = beta / num_topics</cite>.</p></li>
<li><p><strong>learning_decay</strong> – See sklearn documentation.</p></li>
<li><p><strong>learning_offset</strong> – See sklearn documentation.</p></li>
<li><p><strong>learning_method</strong> – See sklearn documentation.</p></li>
<li><p><strong>max_iter</strong> – See sklearn documentation.</p></li>
<li><p><strong>batch_size</strong> – See sklearn documentation.</p></li>
<li><p><strong>verbose</strong> – See sklearn documentation.</p></li>
</ul>
</dd>
</dl>
<p><strong>sklearn_nmf</strong></p>
<p>Fits a model using <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.NMF</span></code>. For more information on available parameters,         please refer to the official documentation: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The dataframe to train the model on (must contain <cite>self.text_col</cite>)</p></li>
<li><p><strong>alpha</strong> – See sklearn documentation.</p></li>
<li><p><strong>l1_ratio</strong> – See sklearn documentation.</p></li>
<li><p><strong>tol</strong> – See sklearn documentation.</p></li>
<li><p><strong>max_iter</strong> – See sklearn documentation.</p></li>
<li><p><strong>shuffle</strong> – See sklearn documentation.</p></li>
</ul>
</dd>
</dl>
<p><strong>gensim_lda</strong></p>
<dl class="simple">
<dt>Fits an LDA model using <code class="xref py py-class docutils literal notranslate"><span class="pre">gensim.models.LdaModel</span></code> or         <code class="xref py py-class docutils literal notranslate"><span class="pre">gensim.models.ldamulticore.LdaMulticore</span></code>. When <cite>use_multicore</cite> is set to <cite>True</cite>, the multicore         implementation will be used, otherwise the standard LDA implementation will be used. For more information on         available parameters, please refer to the official documentation:</dt><dd><ul class="simple">
<li><p>use_multicore=True: <a class="reference external" href="https://radimrehurek.com/gensim/models/ldamulticore.html">https://radimrehurek.com/gensim/models/ldamulticore.html</a></p></li>
<li><p>use_multicore=False: <a class="reference external" href="https://radimrehurek.com/gensim/models/ldamodel.html">https://radimrehurek.com/gensim/models/ldamodel.html</a></p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The dataframe to train the model on (must contain <cite>self.text_col</cite>)</p></li>
<li><p><strong>alpha</strong> – Represents document-topic density. When values are higher, documents will be comprised of more         topics; when values are lower, documents will be primarily comprised of only a few topics. Gensim options are         a bit different than sklearn though; refer to the documentation for the accepted values here.</p></li>
<li><p><strong>beta</strong> – Represents topic-word density. When values are higher, topics will be comprised of more words;         when values are lower, only a few words will be loaded onto each topic. Gensim options are a bit different         than sklearn though; refer to the documentation for the accepted values here. Gensim calls this parameter         <cite>eta</cite>. We renamed it to be consistent with the sklearn implementations.</p></li>
<li><p><strong>chunksize</strong> – See gensim documentation.</p></li>
<li><p><strong>passes</strong> – See gensim documentation.</p></li>
<li><p><strong>decay</strong> – See gensim documentation.</p></li>
<li><p><strong>offset</strong> – See gensim documentation.</p></li>
<li><p><strong>workers</strong> – Number of cores to use (if using multicore)</p></li>
<li><p><strong>use_multicore</strong> – Whether or not to use multicore</p></li>
</ul>
</dd>
</dl>
<p><strong>gensim_hdp</strong></p>
<p>Fits an HDP model using the gensim implementation. Contrary to LDA and NMF, HDP attempts to auto-detect the
correct number of topics. In practice, it actually fits <cite>T</cite> topics (default is 150) but many are extremely rare
or occur only in a very few number of documents. To identify the topics that are actually useful, this function
passes the original DataFrame through the trained model after fitting, and identifies topics that compose at
least 1% of a document in at least 1% of all documents in the corpus. In other words, topics are thrown out if
the number of documents they appear in at a rate of at least 1% are fewer than 1% of the total number of
documents. Subsequent use of the model will only make use of topics that meet this threshold. For more         information on available parameters, please refer to the official documentation: <a class="reference external" href="https://radimrehurek.com/gensim/models/hdpmodel.html">https://radimrehurek.com/gensim/models/hdpmodel.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The dataframe to train the model on (must contain <cite>self.text_col</cite>)</p></li>
<li><p><strong>max_chunks</strong> – See gensim documentation.</p></li>
<li><p><strong>max_time</strong> – See gensim documentation.</p></li>
<li><p><strong>chunksize</strong> – See gensim documentation.</p></li>
<li><p><strong>kappa</strong> – See gensim documentation.</p></li>
<li><p><strong>tau</strong> – See gensim documentation.</p></li>
<li><p><strong>T</strong> – See gensim documentation.</p></li>
<li><p><strong>K</strong> – See gensim documentation.</p></li>
<li><p><strong>alpha</strong> – See gensim documentation.</p></li>
<li><p><strong>beta</strong> – See gensim documentation.</p></li>
<li><p><strong>gamma</strong> – See gensim documentation.</p></li>
<li><p><strong>scale</strong> – See gensim documentation.</p></li>
<li><p><strong>var_converge</strong> – See gensim documentation.</p></li>
</ul>
</dd>
</dl>
<p><strong>corex</strong></p>
<p>Fits a CorEx topic model. Anchors can be provided in the form of a list of lists, with each item
corresponding to a set of words to be used to seed a topic. For example:</p>
<p>The list of anchors cannot be longer than the specified number of topics, and all of the words must
exist in the vocabulary. The <cite>anchor_strength</cite> parameter determines the degree to which the model is able to
override the suggested words based on the data; providing higher values are a way of “insisting” more strongly
that the model keep the provided words together in a single topic. For more information on available         parameters, please refer to the official documentation: <a class="reference external" href="https://github.com/gregversteeg/corex_topic">https://github.com/gregversteeg/corex_topic</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The dataframe to train the model on (must contain <cite>self.text_col</cite>)</p></li>
<li><p><strong>anchors</strong> – A list of lists that contain words that the model should try to group together into topics</p></li>
<li><p><strong>anchor_strength</strong> – The degree to which the provided anchors should be preserved regardless of the data</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">get_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.get_score"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns goodness-of-fit scores for certain models, based on the holdout documents.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following scores are available for the following methods:</p>
<ul class="simple">
<li><p>perplexity: (sklearn_lda only) The model’s perplexity</p></li>
<li><p>score: (sklearn_lda only) The model’s log-likelihood score</p></li>
<li><p>total_correlation: (corex only) The model’s total correlation score</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary with goodness-of-fit scores</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">get_document_topics</code><span class="sig-paren">(</span><em class="sig-param">df</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.get_document_topics"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Takes a DataFrame and returns a document-topic DataFrame (rows=documents, columns=topics)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> – The DataFrame to process (must have <cite>self.text_col</cite> in it)</p></li>
<li><p><strong>min_probability</strong> (<em>float</em>) – (gensim_lda use_multicore=False only) Topics with a probability lower than this         threshold will be filtered out (Default=0.0)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A document-topic matrix</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">get_topics</code><span class="sig-paren">(</span><em class="sig-param">include_weights=False</em>, <em class="sig-param">top_n=10</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.get_topics"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a list, equal in length to the number of topics, where each item is a list of words or word-weight
tuples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include_weights</strong> – Whether or not to include weights along with the ngrams</p></li>
<li><p><strong>top_n</strong> – The number of words to include for each topic</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of lists, where each item is a list of ngrams or ngram-weight tuples</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">print_topics</code><span class="sig-paren">(</span><em class="sig-param">include_weights=False</em>, <em class="sig-param">top_n=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pewanalytics/text/topics.html#TopicModel.print_topics"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Prints the top words for each topic from a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include_weights</strong> – Whether or not to include weights along with the ngrams</p></li>
<li><p><strong>top_n</strong> – The number of words to include for each topic</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="stats.html" class="btn btn-neutral float-left" title="pewanalytics.stats: Statistical Tools" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Pew Research Center

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>